// scripts/sync_exploitdb.js
import { createClient } from '@supabase/supabase-js';
import fetch from 'node-fetch';
import 'dotenv/config';

// --- Config ---
// [FIX] Using the direct RAW URL to avoid "Not Found" errors
const EXPLOITDB_CSV_URL = 'https://raw.githubusercontent.com/offensive-security/exploitdb/main/files_exploits.csv';
const SUPABASE_URL = process.env.SUPABASE_URL;
const SUPABASE_SERVICE_KEY = process.env.SUPABASE_SERVICE_KEY;

if (!SUPABASE_URL || !SUPABASE_SERVICE_KEY) {
  console.error('::ERROR:: SUPABASE_URL or SUPABASE_SERVICE_KEY is not defined.');
  process.exit(1);
}

// Initialize Supabase client
const supabase = createClient(SUPABASE_URL, SUPABASE_SERVICE_KEY, {
  auth: {
      persistSession: false
  }
});

/**
 * Parses a single CSV line into a structured object
 */
function parseCSVLine(line, headers) {
  // [FIX] Using regex to handle commas inside quotes
  const values = line.split(/,(?=(?:(?:[^"]*"){2})*[^"]*$)/);
  
  let obj = {};
  headers.forEach((header, index) => {
    obj[header] = values[index] ? values[index].replace(/"/g, '') : '';
  });

  return obj;
}

/**
 * Transforms the raw CSV object into our database schema
 */
function transformExploitData(raw) {
  if (!raw.id || !raw.description || isNaN(parseInt(raw.id, 10))) { // Added check for valid ID
    return null;
  }
  
  return {
    id: parseInt(raw.id, 10), // Use EDB-ID as the primary key
    title: raw.description,
    date: new Date(raw.date_published).toISOString(),
    author: raw.author,
    type: raw.type,
    platform: raw.platform,
    // Create a URL to the exploit
    url: `https://www.exploit-db.com/exploits/${raw.id}` 
  };
}

/**
 * Main sync function
 */
async function main() {
  console.log('::JOB_START:: Starting Exploit DB sync process...');

  // 1. Fetch the CSV data
  console.log(`::FETCH:: Attempting to fetch: ${EXPLOITDB_CSV_URL}`);
  let csvText;
  try {
    const response = await fetch(EXPLOITDB_CSV_URL);
    if (!response.ok) {
      throw new Error(`Failed to fetch CSV: ${response.statusText} (URL: ${EXPLOITDB_CSV_URL})`);
    }
    csvText = await response.text();
    console.log('::SUCCESS:: Fetched Exploit DB CSV.');
  } catch (error) {
    console.error('::FETCH_ERROR::', error.message);
    process.exit(1);
  }

  // 2. Parse the CSV
  const lines = csvText.split('\n').filter(Boolean); // Filter out empty lines
  const headers = lines[0].split(',').map(h => h.replace(/"/g, '')); // Get headers
  lines.shift(); // Remove header line

  console.log(`::PROCESS:: Found ${lines.length} exploits to process...`);

  const dataToUpsert = lines
    .map(line => parseCSVLine(line, headers))
    .map(transformExploitData)
    .filter(Boolean); // Filter out any null/failed transformations

  if (dataToUpsert.length === 0) {
    console.log('::INFO:: No valid exploit data found to upsert.');
    return;
  }

  // 3. Upsert to Supabase
  // We upsert in chunks to avoid hitting Supabase payload limits
  const CHUNK_SIZE = 500;
  console.log(`::DB_SYNC:: Upserting ${dataToUpsert.length} records in chunks of ${CHUNK_SIZE}...`);

  for (let i = 0; i < dataToUpsert.length; i += CHUNK_SIZE) {
    const chunk = dataToUpsert.slice(i, i + CHUNK_SIZE);
    
    const { error } = await supabase
      .from('exploits')
      .upsert(chunk, {
        onConflict: 'id', // Use 'id' (EDB-ID) as the conflict target
        ignoreDuplicates: false,
      });

    if (error) {
      console.error(`::DB_ERROR:: Failed to upsert chunk ${i / CHUNK_SIZE + 1}:`, error.message);
    } else {
      console.log(`::DB_SUCCESS:: Upserted chunk ${i / CHUNK_SIZE + 1} (${chunk.length} records).`);
    }
  }

  console.log('::JOB_END:: Exploit DB sync process finished.');
}

main().catch(err => {
  console.error('::FATAL_ERROR::', err);
  process.exit(1);
});

